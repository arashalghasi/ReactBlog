after creating the folder we initialize this folder as a new NPM package
npm init -y
then we install the express package
so to use modern javaScript syntax such as the import and export syntax we need to install babel or just going to the package.json file and 
add a line of code "type" : "module",

after having the app object we can define different endpoints and what we want our server to do when one of those endpoints recieves a request
we can use the postman application to test our server
different types of the request:
1- GET -> is used to load information such as an article content or the user's information
2- POST -> is used to create sort of new resource on the server.
3- PUT -> is usually used to update data on the server.
4- ...

one of the resones that we use express is that with the app object we can clearly and easily say which input which type of request is using.
when we use the post as the response we want to work with the information in the body and to work correctly with it in a express app we must 
add a middleware to the app which is basically just extra functionality that the sever automaticaly excecute app.use(express.json());
this is the best way to add information to our request

to fix the problem that every time we should restart our server with the changes of the server.js file there is package called nodemon that fixes
out problem -> npm install nodemon and we want to use this package only in the development not in the production phase so -> npm install nodemon --save-dev
we can use start our sever by npm nodemon "serverfile" and to make this command easier we can go to the package.json file and create a Script
and we can add this in the script section -> "dev": "npx nodemon src/server.js", -> from now we can just type -> npm run dev


mongodb why? is a non relational database which we can push javaScript data into it without the worry how the data is formatted.
to install mongo db see the mongo db documentation in the case of the windows download the windows version and add the path of bin file to the 
windows variables that is not very difficult, I KNOW YOU CAN DO IT:

to have a local db in a folder we can start the db engin by -> mongod --dbpath "\mongo-db-data\"
and then in another bash we can connect to it via -> mongo ---> it opens a terminal that you can write your commands ( maybe your queries who gives a fuck just learn it)


to create a database -> use "the name of the database"

now we insert the data to our local database so - > db.articles.insertMany([
    {
        name: 'learn-node',
        upvotes: 0,
        comments: [],

    },
    {
        name: 'learn-react',
        upvotes: 0,
        comments: [],

    },
    {
        name: 'mongodb',
        upvotes: 0,
        comments: [],

    },
])

To print the data inserted -> db.articles.find() OR db.articles.find({name : 'learn-node'}).pretty() 
name : 'learn-node' is called query object

to interact with the db we need to install the mongodb driver package to our project -> npm install mongodb
this package is allow us to do the same thing inside our node.js code as we did in mongo shell

MongoClinet help us to connect to the database const client = new MongoClient('mongodb://127.0.0.1:27017');

    loads the articles from the db
    const articles = await db.collection('articles').findOne({articleId});

    to update :
        const article = await db.collection('articles').updateOne({name : articleId}, {
        $inc : {upvotes : 1}
    });


to connect to the db and make server.js smaller we will create a file db.js

import{db, connectToDd} from './db.js'; we need to include .js here as long as we added type ="module"

connectToDd(()=>{

    app.listen(PORT, () => {
        console.log(`The server is listening on port ${PORT}`)
    });
    
})

in this case the server will not start up untill we successfully connected to the database

we need to firebase to our backend as well
we want to incorprate firebase auth into our node js server so that we can do things so we can make sure the suers can not upvote an article
mroe than one time  and make sure the users can add comments just when they are logged in
so we need to create a private in firebase that our server can use to connect to firebase auth from our server.

then we need use the credentials to do the server to connect to the firebase/auth -> npm install firebase-admin

admin.initializeApp({
    credential: admin.credential.cert(credentials),
})

here we are saying firebase-admin what credentials should use to connect to the firebase auth

so after connecting to firebase we should protect our endpoint to make sure the user can upvote once and can add comment after loggen in
so from client side we need an auth token which will come by axios with the request -> the auth token is just how the front end proves
that the user is logged in and who they are

we need the expres middleware to automaticaly load the information whenever we recieve a requent to our server
so this is how to make a middleware in express app.use((req,res,next))
the next callback function does when we are done processing things in the the middleware and we want the program to go on to actual route
handlers 

as long as we made the middleware and we have the user in every endpoint we can have the id of the user by const {uid}  = res.user;

the upvote endpoint and comment endpoint have the same criteria which is if the users is not logged in the user can not upvote and add comment
so we need to add a new middleware


You do not believe I was doing 1 hour debuggin for req.headers; it was req.header; just an s porca miseria

So we add the build to backend app.use(express.static(path.join(__dirname, '../build')));
because we added type module to package.json  __dirname will not work by default

we need to add the route handler  like frontend to the backend  using a regular expression as well so 
app.get(/^(?!\/api).+/,(req,res)=>{
    res.sendFile(path.join(__dirname, '../build/index.html'));
})

so all these is for when a browser send a request to our sever that is not going to api route we are going to send back the index.html
which will take care of loading our react script and rendering our react app

now we should run the server and be able to access our react app simply by sending a request to our server

const PORT = process.env.PORT || 8000;
this will allow the hosting platform to specify the port

before publishing we should how mongo db  because we are hosting mongo db localy so we use mongodb atlas
after creating a project in mongoatlas we sould make an environmental file .env

in order to automaticaly load the environment variables from .env file -> npm install dotenv

app.yaml file just going to tell google cloud what sort of environment oru project needs to run in and it is also a good place
to specify environment variables.

so after installing google cloud cli
we need connect to it -> gcloud auth login
we need to choose the project --> gcloud config set project "project name"
to deploy it ---> gcloud app deploy


another option is to publish our app to digital ocean vps

server? it is a computer and i can make it a server because I can make the computer respond to some sort of formulated requests
so with using of node we can ceate a local server 
so for read use these day because of the matter of accessability we use cloud computing
the secret of cloud computing works that I can rent some resource for my personal use is 
virtualization -> dividing a server resource into virtual computers
virtual machine -> digital version of physical computer
vps -> virtual prvate server

how to connect to our ssh bought on digital ocean --> using ssh (socket secure shell) --> private key and public key as like connecting
to the github  which is a communication between two system by sendig request which in this case my wsl has the ssh private key and the vps 
on digital ocean hase the public key  ---> ssh key can be anywhere on the system but by the convension we put it in .ssh folder in home directory
 to make a ssh key ---> ssh-keygen so then we keep safe the private key in our system and to digital ocean by pasting the public key on digital
 ocean site
 ssh to our vps by ssh private key ---> ssh -i ~/.ssh/"name of the privte key" root@<Ip>
 so instead of every time directing and passing the ssh private key let's make it automate ---> using and ssh agent
 so we need to create config file in .ssh and ---> Host * 
                                                    addKeysToAgent yes
                                                    UseKeyChain yes
                                                    IdentityFile ~/.ssh/'privatekey'

so to add a ssh to ssh-keychain ---> ssh.add then the private key

Terminology in networking 
TPC --> transmission control portocol
UDP --> user datagram portocol
ICMP --> internet control message portocol ---> built on tcp/udp 
packet --> unit of data 
DNS --> domain name system
nameserver --> hold DNS records to translate domain names into ip addresses
A record --> maps name to IP addresses
CNAME --> maps name to name
Port --> comminucation endpoint that maps to specific process on network service
firewall:  a network security device that monitors incoming and outgoing network traffic and devices

to see the wellKnown ports : less /etc/services
we can use a protocol nmap to see which port of a system are providing services
to install namp --> sudo apt install nmap
nmap <ipAddress>
to see extra/version information --> nmap -sV <ipAddress>






URL --> uniform resource locator   https://cv.arashalghasi.me/en/fullStack?test=true
cv.arashalghasi.me is subdomain
arashalghasi.me is domain
.me ---> tld (top level domain)
/en/fullStack --> path
test=true --> query parameter


the difference between tcp an update
tcp has the handshake syn-syn ack- ack
udp request - response  using streaming like youtube

some network commands
nslookup "siteURL" to find out where the server is mapped to
to dig these information --->  dig "siteURL"


next buying a domain (nameCheap) with a register --> udpate the nameserver to use digital ocean --> on digital ocean add two records with
your ip address @ and www


first approch in vps
apt update
apt upgrade 
shutdown now -r (flag r for restart)

then to update apt ---> curl https://deb.nodesource.com/setup_19.x | sudo -E bash -

create a user in vps  because we are running as root (whoami command) and we have all the permissions and that is dangerous
to create a new user in vps -->  adduser <username>
to add user to sudo group --> usermod -aG sudo <username>
swich user --> su <username>
check sudo access ---> sudo cat /var/log/auth.log
after creating the user we can use sudo (super user do) allows us to run commands and programs as root

then we want block access to the root to the public so in our home vps directory we want to create a authorized_keys file
and paste the public key in it
so form now on form wsl to connect to vps -->  ssh <vps username not root>@<ip>
to change file permisson in vps --> chmod 644 ~/.ssh/authorized_keys
read,write,execute (4 --> read, 2, write --> 1---> execute) (user,group, every) so in this case user --> read and write, group and everyelse just read
owner    group   everyboyelse  read   write    execute
rwx       rwx      rwx          4       2         1
disable root login --> sudo vi /etc/ssh/sshd_config --> in the file changing PermitRootLogin to ---> no
restart ssh deamon --> sudo service sshd restart


so now we need a web server ---> nginx and apache
nginx --> web server , reverse proxy, forward proxy, email proxy , written in c
reverse proxy --> when a request comes from internet to our vps it should go to a specific place and thats why we need a webserver to handle routing this problem


to install nginx --> sudo apt install nginx
to start nginx ---> sudo service nginx start
then put the ip address your vps digital ocean that you can find it in your droplet and put it in the browser ---> holy shut

nginx configration --> less /etc/nginx/sites-available/default
root /var/www/html  --> base directory for requests

location / {
    blablabla
}

this is the location block and it says where i am going form the path so we can routing within nginx or routing in our server which is node

Application setup
1. Establish application file system
2. Enable version control
3. Create a node.js server

first we need to change ownership of /www of root directroy of our web server nginx ---> sudo chown -R $USER:$USER /var/www
then make an application directory --> mkdir /var/www/app
then git init and pull our code from github

so after creating our node server on piece is missing which is the we have the node server and we have the nginx server but how can they communicate
between them 

so we need to create a new nginx server and proxy request --> sudo vim /etc/nginx/site-enabled-"whatever you call it"

server {
    listen 80 default_server; --> we want to listen on port 80
    listen [::]:80 default_server; --> [::]:80 is IPv6 so we are listening on both

    root /var/www/html;
    index index.html;  ---> this is the file it goes to look for first

    server_name <my_domain>;

    location / {
        proxy_pass http://127.0.0.1:3000; --> at the end the nginx is jsut the route handler it say if you want to go there ok go
    }
}


so we created a virtual host / virtual server  ---> it is a fake server created by nginx ---> we can create infinite server on top of our server
then on top of the server which ..... which is on digital ocean.
 

 so at this point need to modify the nginx config --> /etc/nginx/nginx.config
 it is the virtual host config

 we add include /etc/nginx/sites-enabled/'whatever you called the file'
 to test if nginx works correctly --> sudo nginx -t
 to restrat the web server --> sudo service nginx restart

 so we need a way that node server run continously ---> PM2 (process management)

 to install pm2  --> sudo npm i -g pm2
pm2 start server.js --watch
pm2 list
pm2 save --> gonna save our process list
pm2 startup

(rememeber to isntall node at the first place from apt incase of outdated update apt first)

version control system (vcs) --> git/github 
so ssh to git hub and then ---> make sure the git uses the new ssh key you creted by modifying the ssh config in .ssh
change permission of config to 600 
change the permission of the private key to 600


to have a firewall --> ufw (uncomplicated firewall)
ufw (allow, deny, reject) (ssh,https,http)
---> sudo ufw status
---> sduo ufw allow ssh
---> sddo ufw allow http
---> sudo ufw enable


to keep the operation system uptodate --> sudo apt install unattended-upgrades --> sudo dpkg-reconfigure --priority=low unattended-upgrades

CI/CD --> Continous integration/continous Delivery - Continous deployment
Continous integration --> code changes are validate and maerged back into main branch as often as possible
continous delivery --> code changes are automatically build and ready for production
continous deployment --> builds are automatically deploy to production environment


cron --> execute commands on a schedule --> https://crontab.guru/
to do cron job --> crontab -e
add the new line at the end --> */2 * * * * sh /var/www/app/github.sh 2>&1 | logger -t github.sh
in github.sh ---> #! /usr/bin/bash
                    cd /var/www/app/
                    git pull origin main --ff-only

standard streams :
standard output --> stdout
standard nput ---> stdin
standard error ---> stderr

redirection:
| read from stdout
> write stdout to file
>> append stdout to file
< read form stdin
2>&1 redirect both stderr and stdout


websocekts : Persistent bidirectional connection between client and server

first thing we need go to the default server /etc/ngin/ ... and we should 

location / {
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header connection "upgrade";
    proxy_pass http://127.0.0.1:3000;
}

then we should restart nginx so at this point we made the server to do it for us

to make the server in node 

const express = require('express');
const server = require('http').createServer();
const app = express();

app.get('/',(req,res)=>{
    res.sendFile('index.html',(root:__dirname));
});

server.on('request',app);
server.listen(3000, () => {
    console.log('Listening on 3000!');
});

to install the websocket library ---> npm install ws

const webSocketServer = require('ws').Server;

const wss = new webSocketServer({server : server});

wss.on('connection', function connection(ws){
    const numClients = wss.clients.size;
    console.log('Client Connected', numClients);
    wss.broadcast(`Current visitors: ${numClients}`);

    if (ws.readyState === ws.OPEN){
        ws.send(Welcome to my server');
    }

    ws.on('close'function close(){
        wss.broadcast(`Current visitors: ${numClients}`);
        console.log('A client has disconnected')
    });
});

wss.broadcast = (data) => {
    wss.clients.forEach((client)=>{
        clients.sent(data);
    })
}
